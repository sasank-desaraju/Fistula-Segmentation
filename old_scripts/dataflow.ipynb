{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is to test the workflow and printing of the images by using the following two tutorials:\n",
    "\n",
    "[PyTorch Vizualization Tutorial](https://github.com/Project-MONAI/tutorials/blob/main/3d_segmentation/spleen_segmentation_3d_visualization_basic.ipynb)\n",
    "\n",
    "[PyTorch Lightning Tutorial](https://github.com/Project-MONAI/tutorials/blob/main/3d_segmentation/spleen_segmentation_3d_lightning.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "#import albumentations as A\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "\"\"\"\n",
    "Fistula Segmentation\n",
    "\"\"\"\n",
    "class Configuration:\n",
    "    def __init__(self):\n",
    "        self.init = {\n",
    "            'PROJECT_NAME': 'FistulaSegmentation',\n",
    "            'MODEL_NAME': 'Development',\n",
    "            'RUN_NAME': time.strftime('%Y-%m-%d-%H-%M-%S'),\n",
    "            'WANDB_RUN_GROUP': 'Local',\n",
    "            'FAST_DEV_RUN': True,  # Runs inputted batches (True->1) and disables logging and some callbacks\n",
    "            'MAX_EPOCHS': 3,\n",
    "            'MAX_STEPS': -1,    # -1 means it will do all steps and be limited by epochs\n",
    "            'STRATEGY': 'auto'    # This is the training strategy. Should be 'ddp' for multi-GPU (like HPG)\n",
    "        }\n",
    "        self.etl = {\n",
    "            'DATA_DIR': \"data\",\n",
    "            # Lol what is this?\n",
    "            # HHG2TG lol; deterministic to aid reproducibility\n",
    "            'RANDOM_STATE': 42,\n",
    "        }\n",
    "\n",
    "        self.dataset = {\n",
    "            'DATA_NAME': 'BaseSplit',\n",
    "            'USE_TRANSFORMS': False,\n",
    "            'IMAGE_ROOT': '/media/sasank/LinuxStorage/Dropbox (UFL)/FistulaData/Segmentations/',\n",
    "            'IMAGE_SIZE': (512, 512, 96)\n",
    "        }\n",
    "\n",
    "        self.datamodule = {\n",
    "            'CKPT_FILE': '/media/sasank/LinuxStorage/Dropbox (UFL)/FistulaData/checkpoints/100Epoch87IOU.ckpt',\n",
    "            'BATCH_SIZE': 1,\n",
    "            'FIT_CACHE_NUM': 2,\n",
    "            'SHUFFLE': True,        # Only for training; for test and val this is set in the datamodule script to False\n",
    "            'NUM_WORKERS': 2,\n",
    "            'PIN_MEMORY': False\n",
    "        }\n",
    "\n",
    "\n",
    "        # hyperparameters for training\n",
    "        self.hparams = {\n",
    "            'LOAD_FROM_CHECKPOINT': False,\n",
    "            'learning_rate': 1e-3\n",
    "        }\n",
    "\n",
    "        \"\"\"\n",
    "        #self.transform = None\n",
    "        self.transform = \\\n",
    "        A.Compose([\n",
    "            # Let's do only rigid transformations for now\n",
    "            A.HorizontalFlip(p=0.2),\n",
    "            A.VerticalFlip(p=0.2),\n",
    "            A.RandomRotate90(p=0.2),\n",
    "            A.Transpose(p=0.2),\n",
    "        ],\n",
    "        p=1.0)\n",
    "        \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Configuration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset (let's just do Dataset and not do Datamodule yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#self.config = config\n",
    "batch_size = config.datamodule['BATCH_SIZE']\n",
    "#self.log(batch_size)\n",
    "num_workers = config.datamodule['NUM_WORKERS']\n",
    "pin_memory = config.datamodule['PIN_MEMORY']\n",
    "shuffle = config.datamodule['SHUFFLE']\n",
    "\n",
    "# TODO: check train dataset length and integrity\n",
    "# TODO: check val dataset length and integrity\n",
    "\n",
    "# Create train, val, test splits of the data\n",
    "self.train_data = pd.read_csv(os.path.join(self.config.etl['DATA_DIR'], self.config.dataset['DATA_NAME'], 'train' + '_' + self.config.dataset['DATA_NAME'] + '.csv'))\n",
    "self.val_data = pd.read_csv(os.path.join(self.config.etl['DATA_DIR'], self.config.dataset['DATA_NAME'], 'val' + '_' + self.config.dataset['DATA_NAME'] + '.csv'))\n",
    "self.test_data = pd.read_csv(os.path.join(self.config.etl['DATA_DIR'], self.config.dataset['DATA_NAME'], 'test' + '_' + self.config.dataset['DATA_NAME'] + '.csv'))\n",
    "\n",
    "resample_model = os.path.join(self.config.dataset['IMAGE_ROOT'], '7/7_image.nii.gz')\n",
    "\n",
    "# For each splits, create a list of dictionaries containing the image paths, label paths, and patient IDs\n",
    "# Have both image and label paths prepended by the self.config.dataset['IMAGE_ROOT']\n",
    "self.train_files = [{'image': os.path.join(self.config.dataset['IMAGE_ROOT'], self.train_data.iloc[i]['image']),\n",
    "                'label': os.path.join(self.config.dataset['IMAGE_ROOT'], self.train_data.iloc[i]['label']),\n",
    "                'resample_model': resample_model,\n",
    "                'patient_id': self.train_data.iloc[i]['patient_id']} for i in range(len(self.train_data))]\n",
    "self.val_files = [{'image': os.path.join(self.config.dataset['IMAGE_ROOT'], self.val_data.iloc[i]['image']),\n",
    "                'label': os.path.join(self.config.dataset['IMAGE_ROOT'], self.val_data.iloc[i]['label']),\n",
    "                'resample_model': resample_model,\n",
    "                'patient_id': self.val_data.iloc[i]['patient_id']} for i in range(len(self.val_data))]\n",
    "self.test_files = [{'image': os.path.join(self.config.dataset['IMAGE_ROOT'], self.test_data.iloc[i]['image']),\n",
    "                'label': os.path.join(self.config.dataset['IMAGE_ROOT'], self.test_data.iloc[i]['label']),\n",
    "                'resample_model': resample_model,\n",
    "                'patient_id': self.test_data.iloc[i]['patient_id']} for i in range(len(self.test_data))]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jtml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
