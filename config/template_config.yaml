defaults:
- _self_
- override hydra/launcher: submitit_slurm
# - hydra/output: default

# model: llama3.1:70b
model: ???
# model_extension: "_${model.split(':')[1]}"  # Interpolates to get "_70b"
ground_truth: ???
context: ???
description: ???
tasks: instructions.tasks5

hydra:
  run:
    dir: experiments/${now:%Y-%m-%d}/${model}/${now:%H-%M-%S}
  sweep:
    dir: experiments/${now:%Y-%m-%d}/${model}/${now:%H-%M-%S}
    # dir: multirun/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.num}
    # subdir: ${model}
  launcher:
    name: ${hydra.job.name}
    submitit_folder: ${hydra.sweep.dir}/.submitit/%j
    # submitit_folder: test_dir/
    timeout_min: 60
    nodes: 1
    tasks_per_node: 1
    cpus_per_task: 1
    gpus_per_node: null
    mem_gb: 32
    stderr_to_stdout: false
    _target_: hydra_plugins.hydra_submitit_launcher.submitit_launcher.SlurmLauncher
    partition: gpu
    qos: prismap-ai-core
    account: prismap-ai-core
    gres: gpu:a100:1
    # gres: gpu
    # comment: null
    # constraint: null
    # exclude: null
    # cpus_per_gpu: null
    # gpus_per_task: null
    # mem_per_gpu: null
    # mem_per_cpu: null
    # signal_delay_s: 120
    # max_num_timeout: 0
    additional_parameters: {"mail-user": "sasank.desaraju@ufl.edu", "mail-type": "END,FAIL"}
    # array_parallelism: 256
    # setup: null
  sweeper:
    _target_: hydra._internal.core_plugins.basic_sweeper.BasicSweeper
    # max_batch_size: null
    # params: null

exp_dir: ${hydra.run.dir}
